{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 02. Learning LangGraph - Chat Executor"
      ],
      "metadata": {
        "id": "E5TwMbBvpk4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AAoQEqlXGrWi"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet -U langchain langchain_openai langgraph langchainhub langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-zqCF74QW2K",
        "outputId": "643f30b8-99b9-421b-a77c-822942615a0d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "modified from https://github.com/langchain-ai/langgraph/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb"
      ],
      "metadata": {
        "id": "BL-NMZ7ve3Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_02\"\n"
      ],
      "metadata": {
        "id": "guac0Zh7Gz4Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ShMnHhdZQOuz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The model"
      ],
      "metadata": {
        "id": "nGkci88EkVwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0, streaming=True)"
      ],
      "metadata": {
        "id": "58MBHiikkQDb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools"
      ],
      "metadata": {
        "id": "2_I3howTkdUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
        "import random\n",
        "\n",
        "@tool(\"lower_case\", return_direct=True)\n",
        "def to_lower_case(input:str) -> str:\n",
        "  \"\"\"Returns the input as all lower case.\"\"\"\n",
        "  return input.lower()\n",
        "\n",
        "@tool(\"random_number\", return_direct=True)\n",
        "def random_number_maker(input:str) -> str:\n",
        "    \"\"\"Returns a random number between 0-100. input the word 'random'\"\"\"\n",
        "    return random.randint(0, 100)\n",
        "\n",
        "tools = [to_lower_case,random_number_maker]"
      ],
      "metadata": {
        "id": "OLeIVeaEJltj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "\n",
        "tool_executor = ToolExecutor(tools)"
      ],
      "metadata": {
        "id": "IQkcYH78mRmk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "model = model.bind_functions(functions)"
      ],
      "metadata": {
        "id": "aqJWD8X1ke5q"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AgentState"
      ],
      "metadata": {
        "id": "DRyUkY3cktGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ],
      "metadata": {
        "id": "I1H-xbWNkpSv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes"
      ],
      "metadata": {
        "id": "FbQtOmzQk27f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.agents import AgentFinish\n",
        "from langgraph.prebuilt import ToolInvocation\n",
        "import json\n",
        "from langchain_core.messages import FunctionMessage\n",
        "\n",
        "# Define the function that determines whether to continue or not\n",
        "def should_continue(state):\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "    # If there is no function call, then we finish\n",
        "    if \"function_call\" not in last_message.additional_kwargs:\n",
        "        return \"end\"\n",
        "    # Otherwise if there is, we continue\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state):\n",
        "    messages = state['messages']\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Define the function to execute tools\n",
        "def call_tool(state):\n",
        "    messages = state['messages']\n",
        "    # Based on the continue condition\n",
        "    # we know the last message involves a function call\n",
        "    last_message = messages[-1]\n",
        "    # We construct an ToolInvocation from the function_call\n",
        "    action = ToolInvocation(\n",
        "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
        "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
        "    )\n",
        "    print(f\"The agent action is {action}\")\n",
        "    # We call the tool_executor and get back a response\n",
        "    response = tool_executor.invoke(action)\n",
        "    print(f\"The tool result is: {response}\")\n",
        "    # We use the response to create a FunctionMessage\n",
        "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [function_message]}"
      ],
      "metadata": {
        "id": "2HoxaGZbkvi5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph"
      ],
      "metadata": {
        "id": "UvaLZp3jlM9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", call_tool)\n",
        "\n",
        "# Set the entrypoint as `agent` where we start\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge('action', 'agent')\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "2Vxw2TOClGYm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run it"
      ],
      "metadata": {
        "id": "AAVFBk3GlY5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Define the system message once\n",
        "system_message = SystemMessage(content=\"you are a helpful assistant\")\n",
        "\n",
        "# Define the queries\n",
        "queries = [\n",
        "    \"give me a random number and then write in words and make it lower case\",\n",
        "    \"please write 'Merlion' in lower case\",\n",
        "    \"what is a Merlion?\"\n",
        "]\n",
        "\n",
        "# Collect outputs\n",
        "outputs = []\n",
        "\n",
        "for query in queries:\n",
        "    user_message = HumanMessage(content=query)\n",
        "    inputs = {\"messages\": [system_message, user_message]}\n",
        "\n",
        "    # Invoke the app and store the result\n",
        "    result = app.invoke(inputs)\n",
        "\n",
        "    # Collect the result in outputs\n",
        "    outputs.append(result)\n",
        "\n",
        "# Print all outputs\n",
        "for i, output in enumerate(outputs):\n",
        "    print(f\"Output for query {i + 1}: {output}\")\n"
      ],
      "metadata": {
        "id": "t6nGDuI6g-Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1619ae0d-f992-49cb-f93b-fe18f9b16bcb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The agent action is tool='random_number' tool_input={'input': 'random'}\n",
            "The tool result is: 64\n",
            "The agent action is tool='lower_case' tool_input={'input': 'sixty four'}\n",
            "The tool result is: sixty four\n",
            "The agent action is tool='lower_case' tool_input={'input': 'Merlion'}\n",
            "The tool result is: merlion\n",
            "Output for query 1: {'messages': [SystemMessage(content='you are a helpful assistant'), HumanMessage(content='give me a random number and then write in words and make it lower case'), AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-0b2c4f81-fd68-43a0-9b16-7a41c184efbe-0'), FunctionMessage(content='64', name='random_number'), AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"sixty four\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-1452cc03-9bc2-4fc0-b57d-e2cbb3e649b1-0'), FunctionMessage(content='sixty four', name='lower_case'), AIMessage(content='The random number is 64, written in words it is \"sixty four\", and in lower case it is \"sixty four\".', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-1f5116aa-dd07-492e-8872-4807bcc257f8-0')]}\n",
            "Output for query 2: {'messages': [SystemMessage(content='you are a helpful assistant'), HumanMessage(content=\"please write 'Merlion' in lower case\"), AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"Merlion\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-7f4fb877-8c17-481c-a724-eb79ff5e5510-0'), FunctionMessage(content='merlion', name='lower_case'), AIMessage(content='The word \"Merlion\" in lower case is \"merlion\".', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-cdea7db5-9565-4dc8-a2d0-de65cb8122df-0')]}\n",
            "Output for query 3: {'messages': [SystemMessage(content='you are a helpful assistant'), HumanMessage(content='what is a Merlion?'), AIMessage(content=\"A Merlion is a mythical creature with the head of a lion and the body of a fish. It is a symbol of Singapore and is often depicted as a statue with a lion's head and a fish's body. The Merlion represents the city's history as a fishing village and its transformation into a modern metropolis.\", response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-4a29c30f-799b-44ce-8242-f88feab920c6-0')]}\n"
          ]
        }
      ]
    }
  ]
}